{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/homepage-experiment-data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Day</th>\n",
       "      <th>Control Cookies</th>\n",
       "      <th>Control Downloads</th>\n",
       "      <th>Control Licenses</th>\n",
       "      <th>Experiment Cookies</th>\n",
       "      <th>Experiment Downloads</th>\n",
       "      <th>Experiment Licenses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1764</td>\n",
       "      <td>246</td>\n",
       "      <td>1</td>\n",
       "      <td>1850</td>\n",
       "      <td>339</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1541</td>\n",
       "      <td>234</td>\n",
       "      <td>2</td>\n",
       "      <td>1590</td>\n",
       "      <td>281</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1457</td>\n",
       "      <td>240</td>\n",
       "      <td>1</td>\n",
       "      <td>1515</td>\n",
       "      <td>274</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1587</td>\n",
       "      <td>224</td>\n",
       "      <td>1</td>\n",
       "      <td>1541</td>\n",
       "      <td>284</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1606</td>\n",
       "      <td>253</td>\n",
       "      <td>2</td>\n",
       "      <td>1643</td>\n",
       "      <td>292</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Day  Control Cookies  Control Downloads  Control Licenses  \\\n",
       "0    1             1764                246                 1   \n",
       "1    2             1541                234                 2   \n",
       "2    3             1457                240                 1   \n",
       "3    4             1587                224                 1   \n",
       "4    5             1606                253                 2   \n",
       "\n",
       "   Experiment Cookies  Experiment Downloads  Experiment Licenses  \n",
       "0                1850                   339                    3  \n",
       "1                1590                   281                    2  \n",
       "2                1515                   274                    1  \n",
       "3                1541                   284                    2  \n",
       "4                1643                   292                    3  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking the Invariant Metric\n",
    "What is the p-value for the test on the number of cookies assigned to each group?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "control_cookies = df['Control Cookies'].values\n",
    "experiment_cookies = df['Experiment Cookies'].values\n",
    "\n",
    "control_size = np.sum(control_cookies)\n",
    "experiment_size = np.sum(experiment_cookies)\n",
    "\n",
    "number_observations = control_size + experiment_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46851, 47346)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "control_size, experiment_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulate outcomes under null, compare to observed outcome\n",
    "p = 0.5\n",
    "simulation_size = 200_000\n",
    "\n",
    "theorical_control_obs = np.random.binomial(number_observations, p, simulation_size)\n",
    "\n",
    "# two-tailed hyphotesis testing\n",
    "p_value = np.logical_or(\n",
    "    theorical_control_obs <= control_size, \n",
    "    theorical_control_obs >= (number_observations - control_size)\n",
    ").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10707"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great job! Even though there's a few hundred more cookies in the experimental group than the control group, the difference between groups isn't statistically significant. We should feel fine about moving on to test the evaluation metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking the Evaluation Metric I\n",
    "What is the p-value for the test on the download rate between groups?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get number of trials and overall 'success' rate under null\n",
    "control_downloads = df['Control Downloads'].values\n",
    "experiment_downloads = df['Experiment Downloads'].values\n",
    "\n",
    "# calculating proportions per group\n",
    "control_download_prop = np.sum(control_downloads) / control_size\n",
    "experiment_download_prop = np.sum(experiment_downloads) / experiment_size\n",
    "\n",
    "# joining the proportions following the null aka the data as a whole (null = no difference)\n",
    "group_download_prop_observed = (control_download_prop + experiment_download_prop)/2\n",
    "\n",
    "# success rate = joined proportions\n",
    "p_null = group_download_prop_observed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17088889349981923"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p_null is calculated assuming the data follows the null. The null says there's nor difference, therefore, we could mix the control and experiment proportions (since that's what the null says) and that would be the actual **success rate** under the null."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulate outcomes under null, compare to observed outcome\n",
    "n_trials = 200_000\n",
    "\n",
    "# create theorical distributions ...\n",
    "theorical_control_downloads = np.random.binomial(control_size, p_null, n_trials)\n",
    "theorical_exp_downloads = np.random.binomial(experiment_size, p_null, n_trials)\n",
    "\n",
    "# ... and perform the same operation as in the previous cell\n",
    "# here we don't `np.sum` since each of the elements in the array (numerator) are the actual success counts\n",
    "theorical_control_download_prop = theorical_control_downloads / control_size\n",
    "theorical_experiment_download_prop = theorical_exp_downloads / experiment_size\n",
    "\n",
    "# calculate our test statistic (proportion difference) for both the theorical and observed distributions\n",
    "# array\n",
    "theorical_diff_prop = theorical_experiment_download_prop - theorical_control_download_prop\n",
    "# number\n",
    "observed_diff_prop = experiment_download_prop - control_download_prop\n",
    "\n",
    "# get the probability of getting values as extremes as the one observed\n",
    "p_value = (theorical_diff_prop >= observed_diff_prop).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The download rate is very much statistically significant, beyond all conventional signficance levels. If you used the whole data, you should have gotten a z-score of about 8.55. If you were clever (see the next question) you should have gotten a z-score of about 7.13."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking the Evaluation Metric II\n",
    "What is the p-value for the test on the license purchasing rate between groups?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correcting the size of the groups for the license feature \n",
    "# (check out the course notes about why we do this)\n",
    "df_corrected = df[df.Day <= 21]\n",
    "control_size_corrected = np.sum(df_corrected['Control Cookies'].values)\n",
    "experiment_size_corrected = np.sum(df_corrected['Experiment Cookies'].values)\n",
    "\n",
    "# get number of trials and overall 'success' rate under null\n",
    "control_licenses = df_corrected['Control Licenses'].values\n",
    "experiment_licenses = df_corrected['Experiment Licenses'].values\n",
    "\n",
    "# calculating proportions per group\n",
    "control_licenses_prop = np.sum(control_licenses) / control_size_corrected\n",
    "experiment_licenses_prop = np.sum(experiment_licenses) / experiment_size_corrected\n",
    "\n",
    "# joining the proportions following the null aka the data as a whole (null = no difference)\n",
    "group_licenses_prop_observed = (control_licenses_prop + experiment_licenses_prop)/2\n",
    "\n",
    "# success rate = joined proportions\n",
    "p_null = group_licenses_prop_observed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.013201281858188361"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulate outcomes under null, compare to observed outcome\n",
    "n_trials = 500_000\n",
    "\n",
    "# create theorical distributions\n",
    "theorical_control_licenses = np.random.binomial(control_size_corrected, p_null, n_trials)\n",
    "theorical_exp_licenses = np.random.binomial(experiment_size_corrected, p_null, n_trials)\n",
    "\n",
    "# calculate theorical proportions per group\n",
    "theorical_control_licences_prop = theorical_control_licenses / control_size_corrected\n",
    "theorical_experiment_licences_prop = theorical_exp_licenses / experiment_size_corrected\n",
    "\n",
    "# calculate test statistic (proportion difference) for both the theorical and observed distributions\n",
    "theorical_diff_prop = theorical_experiment_licences_prop - theorical_control_licences_prop\n",
    "observed_diff_prop = experiment_licenses_prop - control_licenses_prop\n",
    "\n",
    "# get the probability of getting values as extremes as the one observed\n",
    "p_value = (theorical_diff_prop >= observed_diff_prop).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.429264"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
