{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Types of Studies\n",
    "- If you have a lot of control over features, then you have an **experiment**.\n",
    "- If you have no control over the features, then you have an **observational study**.\n",
    "- If you have some control, then you have a **quasi-experiment**.\n",
    "\n",
    "### Types of Experiments\n",
    "- between-subjects experiment: each experimental unit sees only one of the conditions being used in the experiment.\n",
    "- within-subjects experiment: each experimental unit sees both conditions.\n",
    "- Factorial designs: multiple features of interest. Example, with two independent manipulations \"X\" and \"Y\", we have four conditions: \"control\", \"X only\", \"Y only\", \"X and Y\".\n",
    "\n",
    "### Types of Sampling\n",
    "**Probabilistic Sampling**  \n",
    "- Simple Random Sampling\n",
    "- Stratified Random Sampling\n",
    "**Non-Probabilistic Sampling**  \n",
    "- convenience sample: records information from readily available units\n",
    "\n",
    "### Measuring Outcomes\n",
    "The goals of a study may not be the same as the way you evaluate the study's success. \n",
    "- Evaluation Metric aka KPI (aka Dependent Variable? Sometimes are the same)\n",
    "- Invariant Metric: metrics that we hope will not be different between groups  \n",
    "\n",
    "Ex: \n",
    "- goal: increase user satisfaction\n",
    "- evaluation metric: number of purcheases in the app\n",
    "- invariant metric: if in a control treatment experiment the number of sessions per group should be near to 50/50. \n",
    "\n",
    "### Creating Metrics\n",
    "- Funnels and Web based experiments\n",
    "- Typically, the funnel ends at the place where your main evaluation metric is recorded.  \n",
    "Ex:  \n",
    "    - Visit the site homepage\n",
    "    - Search for a desired product or click on a product category\n",
    "    - Click on a product image\n",
    "    - Add the product to the cart\n",
    "    - Check out and finalize purchase\n",
    "\n",
    "**Unit of Diversion**  \n",
    "We need to figure out a way to assign users to either a control group or experimental group\n",
    "- Event-based diversion\n",
    "- Cookie-based diversion\n",
    "- Account-based diversion \n",
    "\n",
    "### Controlling Variables\n",
    "- Watch out for *confoundings*.\n",
    "- Correlation does not imply causation.\n",
    "\n",
    "### Checking Validity\n",
    "- Construct Validity: how well one's goals are aligned to the evaluation metrics used to evaluate it.\n",
    "- Internal Validity (confoundings): the degree to which a causal relationship can be derived from an experiment's results.\n",
    "- External Validity: the ability of an experimental outcome to be generalized to a broader population\n",
    "\n",
    "### Checking Bias\n",
    "- Sampling bias: those that cause our observations to not be representative of the population.\n",
    "    - Self-selection bias. The types of people that respond to a survey might be qualitatively very different from those that do not.\n",
    "    - Survivor bias. Related to missing data. Where losses or dropout of observed units is not accounted for in an analysis.\n",
    "- Novility bias: A novelty effect is one that causes observers to change their behavior simply because they're seeing something new. \n",
    "- Order bias: when running a within-subjects experiment.The order in which conditions are completed could have an effect on participant responses.\n",
    "    - A primacy effect is one that affects early conditions, perhaps biasing them to be recalled better or to serve as anchor values for later conditions. \n",
    "    - A recency effect is one that affects later conditions, perhaps causing bias due to being fresher in memory or task fatigue.\n",
    "- Experimenter bias: the presence or knowledge of the experimenter can affect participants' behaviors or performance.\n",
    "    - the double-blind design hides condition information from both the administrator and participant in order to have a strong rein on experimenter-based biases.\n",
    "    \n",
    "### Ethics in Experimentation\n",
    "- Minimize participant risk\n",
    "- Minimize participant risk\n",
    "- Provide informed consent\n",
    "- Handle sensitive data appropriately\n",
    "\n",
    "---\n",
    "\n",
    "### Early stopping\n",
    "- When an experiment is already defined (evaluation metrics, sample size, power) and being conducted and one takes a peek at how the experiment is going (is there evidence for or against the null?). \n",
    "- One can control for errors in this sceneario by applying some corrections accounted in a **multiple comparison problem**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
