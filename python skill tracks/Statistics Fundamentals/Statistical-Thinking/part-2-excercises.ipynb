{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bootstrap confidence intervals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Excersice 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Michelson's speed of light measurements \n",
    "michelson_speed_of_light = pd.read_csv('datasets/michelson_speed_of_light.csv', index_col=0)\n",
    "michelson_speed_of_light = michelson_speed_of_light['velocity of light in air (km/s)']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part 1**  \n",
    "In this exercise, you will compute a bootstrap estimate of the probability density function of the mean annual rainfall at the Sheffield Weather Station. Remember, we are estimating the mean annual rainfall we would get if the Sheffield Weather Station could repeat all of the measurements from 1883 to 2015 over and over again. `This is a probabilistic estimate of the mean`. You will plot the PDF as a histogram, and you will see that it is Normal.\n",
    "\n",
    "In fact, it can be shown theoretically that under not-too-restrictive conditions, the value of the mean will always be Normally distributed. (This does not hold in general, just for the mean and a few other statistics.) `The standard deviation of the distribution of the mean, called the standard error of the mean, or SEM`, is given by the standard deviation of the data divided by the square root of the number of data points. I.e., for a data set, `sem = np.std(data) / np.sqrt(len(data))`. Using hacker statistics, you get this same result without the need to derive it, but you will verify this result from your bootstrap replicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part 2: Confidence intervals of rainfall data** \n",
    "\n",
    "A confidence interval gives upper and lower bounds on the range of parameter values you might expect to get if we repeat our measurements. For named distributions, you can compute them analytically or look them up, but one of the many beautiful properties of the bootstrap method is that you can take percentiles of your bootstrap replicates to get your confidence interval. Conveniently, you can use the np.percentile() function.\n",
    "\n",
    "Use the bootstrap replicates you just generated to compute the 95% confidence interval. That is, give the 2.5th and 97.5th percentile of your bootstrap replicates stored as bs_replicates. What is the 95% confidence interval?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part 3: Bootstrap replicates of other statistics**  \n",
    "We saw in a previous exercise that the mean is Normally distributed. This does not necessarily hold for other statistics, but no worry: as hackers, we can always take bootstrap replicates! In this exercise, you'll generate bootstrap replicates for the variance of the annual rainfall at the Sheffield Weather Station and plot the histogram of the replicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyphotesis Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Excersice 1 - Permutation Testing\n",
    "**Data:**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('datasets/frog_tongue.csv',header=14,usecols=['ID','impact force (mN)'])\n",
    "df.columns = ['ID','impact_force']\n",
    "df = df[(df.ID=='II') | (df.ID=='IV')]\n",
    "df.impact_force /= 1000\n",
    "df.replace(to_replace='II',value='A',inplace=True)\n",
    "df.replace(to_replace='IV',value='B',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "force_a = df['impact_force'][df.ID=='A'].values\n",
    "force_b = df['impact_force'][df.ID=='B'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**Part 1: Look before you leap: EDA before hypothesis testing**  \n",
    "Kleinteich and Gorb (Sci. Rep., 4, 5225, 2014) performed an interesting experiment with South American horned frogs. They held a plate connected to a force transducer, along with a bait fly, in front of them. They then measured the impact force and adhesive force of the frog's tongue when it struck the target.\n",
    "\n",
    "Frog A is an adult and Frog B is a juvenile. The researchers measured the impact force of 20 strikes for each frog. In the next exercise, we will test the hypothesis that the two frogs have the same distribution of impact forces. But, remember, it is important to do EDA first! Let's make a bee swarm plot for the data. They are stored in a Pandas data frame, df, where column ID is the identity of the frog and column impact_force is the impact force in Newtons (N)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part 2: Permutation test on frog data**  \n",
    "The average strike force of Frog A was 0.71 Newtons (N), and that of Frog B was 0.42 N for a difference of 0.29 N. It is possible the frogs strike with the same force and this observed difference was by chance. You will compute the probability of getting at least a 0.29 N difference in mean strike force under the hypothesis that the distributions of strike forces for the two frogs are identical. We use a permutation test with a test statistic of the difference of means to test this hypothesis.\n",
    "\n",
    "For your convenience, the data has been stored in the arrays force_a and force_b."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Excersice 2 - Bootstrap Testing\n",
    "**Data:**  \n",
    "Same as previous excersice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part 1: A one-sample bootstrap hypothesis test**  \n",
    "Another juvenile frog was studied, Frog C, and you want to see if Frog B and Frog C have similar impact forces. Unfortunately, you do not have Frog C's impact forces available, but you know they have a mean of 0.55 N. `Because you don't have the original data, you cannot do a permutation test`, and `you cannot assess the hypothesis that the forces from Frog B and Frog C come from the SAME DISTRIBUTION`. You will therefore `test another, less restrictive hypothesis`: `The mean strike force of Frog B is equal to that of Frog C.`\n",
    "\n",
    "To set up the bootstrap hypothesis test, you will take the mean as our test statistic. Remember, your goal is to calculate the probability of getting a mean impact force less than or equal to what was observed for Frog B if the hypothesis that the true mean of Frog B's impact forces is equal to that of Frog C is true. You first translate all of the data of Frog B such that the mean is 0.55 N. This involves `adding the mean force of Frog C and subtracting the mean force of Frog B from each measurement of Frog B`. `This leaves other properties of Frog B's distribution, such as the variance, unchanged.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part 2: A two-sample bootstrap hypothesis test for difference of means**  \n",
    "We now want to test the hypothesis that Frog A and Frog B have the same mean impact force but not necessarily the same distribution, `which is also impossible with a permutation test (since it is for distributions not for independent values).`\n",
    "\n",
    "To do the two-sample bootstrap test, we shift both arrays to have the same mean, since we are simulating the hypothesis that their means are, in fact, equal. We then draw bootstrap samples out of the shifted arrays and compute the difference in means. This constitutes a bootstrap replicate, and we generate many of them. The p-value is the fraction of replicates with a difference in means greater than or equal to what was observed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part 3: A bootstrap test for identical distributions**  \n",
    "Given that we're testing that the samples come from the same distribution, using `choice` or `permutation` should be equivalent operations if both samples come from the same distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyphotesis Testing - More Excersices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Excersice 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The vote for the Civil Rights Act in 1964**  \n",
    "The Civil Rights Act of 1964 was one of the most important pieces of legislation ever passed in the USA. Excluding \"present\" and \"abstain\" votes, 153 House Democrats and 136 Republicans voted yea. However, 91 Democrats and 35 Republicans voted nay. Did party affiliation make a difference in the vote?\n",
    "\n",
    "To answer this question, you will evaluate the hypothesis that the party of a House member has no bearing on his or her vote. You will use the fraction of Democrats voting in favor as your test statistic and evaluate the probability of observing a fraction of Democrats voting in favor at least as small as the observed fraction of 153/244. `(That's right, at least as small as. In 1964, it was the Democrats who were less progressive on civil rights issues.)` To do this, permute the party labels of the House voters and then arbitrarily divide them into \"Democrats\" and \"Republicans\" and compute the fraction of Democrats voting yea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Excersice 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data:** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('datasets/mlb_nohitters.csv',usecols=['game_number']).diff(1) - 1\n",
    "df['game_number'] = df['game_number'].fillna(-1).astype(int)\n",
    "nht_dead = df['game_number'].iloc[:91].values\n",
    "nht_live = df['game_number'].iloc[91:].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part 1: A time-on-website analog**  \n",
    "A/B test: Determine if these rule changes resulted in a slower rate of no-hitters (i.e., longer average time between no-hitters) (**of the distribution of no-hitters**)\n",
    "\n",
    "It turns out that you already did a hypothesis test analogous to an A/B test where you are interested in how much time is spent on the website before and after an ad campaign. The frog tongue force (a continuous quantity like time on the website) is an analog. \"Before\" = Frog A and \"after\" = Frog B. Let's practice this again with something that actually is a before/after scenario.\n",
    "\n",
    "We return to the no-hitter data set. In 1920, Major League Baseball implemented important rule changes that ended the so-called dead ball era. Importantly, the pitcher was no longer allowed to spit on or scuff the ball, an activity that greatly favors pitchers. In this problem you will perform an A/B test to determine if these rule changes resulted in a slower rate of no-hitters (i.e., longer average time between no-hitters) using the difference in mean inter-no-hitter time as your test statistic. The inter-no-hitter times for the respective eras are stored in the arrays nht_dead and nht_live, where \"nht\" is meant to stand for \"no-hitter time.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part 2: What should you have done first?**  \n",
    "That was a nice hypothesis test you just did to check out whether the rule changes in 1920 changed the rate of no-hitters. But what should you have done with the data first?\n",
    "\n",
    "Performed EDA, perhaps plotting the ECDFs of inter-no-hitter times in the dead ball and live ball eras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Excersice 3\n",
    "**Simulating a null hypothesis concerning correlation**  \n",
    "The observed correlation between female illiteracy and fertility in the data set of 162 countries may just be by chance; `the fertility of a given country may actually be totally independent of its illiteracy`. You will test this null hypothesis in the next exercise.\n",
    "\n",
    "To do the test, you need to `simulate the data assuming the null hypothesis is true`. Of the following choices, which is the best way to do it?\n",
    "\n",
    "1. Choose 162 random numbers to represent the illiteracy rate and 162 random numbers to represent the corresponding fertility rate.\n",
    "\n",
    "2. Do a pairs bootstrap: Sample pairs of observed data with replacement to generate a new set of (illiteracy, fertility) data.\n",
    "\n",
    "3. Do a bootstrap sampling in which you sample 162 illiteracy values with replacement and then 162 fertility values with replacement.\n",
    "\n",
    "4. Do a permutation test: Permute the illiteracy values but leave the fertility values fixed to generate a new set of (illiteracy, fertility) data.\n",
    "\n",
    "5. Do a permutation test: Permute both the illiteracy and fertility values to generate a new set of (illiteracy, fertility data).\n",
    "\n",
    "#### Hint\n",
    "Randomly choosing numbers is not an option because they would have nothing to do with the measured data. In general, permutation tests are preferred to bootstrap sampling because they are exact and make use of all the data. It is a valid choice to permute both illiteracy as well as fertility values, but this is computationally inefficient; permuting either illiteracy or fertility will suffice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Excercise 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "literacy = pd.read_csv('datasets/female_literacy_fertility.csv')\n",
    "illiteracy = 100 - literacy['female literacy']\n",
    "fertility = literacy['fertility']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pearson_r(x, y):\n",
    "    \"\"\"Compute Pearson correlation coefficient between two arrays.\"\"\"\n",
    "    corr_mat = np.corrcoef(x,y)\n",
    "    return corr_mat[0,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hypothesis test on Pearson correlation**  \n",
    "The observed correlation between female illiteracy and fertility may just be by chance; the fertility of a given country may actually be totally independent of its illiteracy. You will test this hypothesis. To do so, permute the illiteracy values but leave the fertility values fixed. `This simulates the hypothesis that they are totally independent of each other`. For each permutation, compute the Pearson correlation coefficient and assess how many of your permutation replicates have a Pearson correlation coefficient greater than the observed one.\n",
    "\n",
    "The function pearson_r() that you wrote in the prequel to this course for computing the Pearson correlation coefficient is already in your name space.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Excercise 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('datasets/bee_sperm.csv',header=3)\n",
    "control = df['Alive Sperm Millions'][:208].values * 2\n",
    "treated = df['Alive Sperm Millions'][208:].values * 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part 1: Do neonicotinoid insecticides have unintended consequences?**  \n",
    "As a final exercise in hypothesis testing before we put everything together in our case study in the next chapter, you will investigate the effects of neonicotinoid insecticides on bee reproduction. These insecticides are very widely used in the United States to combat aphids and other pests that damage plants.\n",
    "\n",
    "In a recent study, Straub, et al. (Proc. Roy. Soc. B, 2016) investigated the effects of neonicotinoids on the sperm of pollinating bees. `In this and the next exercise, you will study how the pesticide treatment affected the count of live sperm per half milliliter of semen.`\n",
    "\n",
    "First, we will do EDA, as usual. Plot ECDFs of the alive sperm count for untreated bees (stored in the Numpy array control) and bees treated with pesticide (stored in the Numpy array treated)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part 2 Bootstrap hypothesis test on bee sperm counts**  \n",
    "Now, you will test the following `hypothesis`: `On average, male bees treated with neonicotinoid insecticide have the same number of active sperm per milliliter of semen than do untreated male bees`. You will use the difference of means as your test statistic.\n",
    "\n",
    "For your reference, the call signature for the draw_bs_reps() function you wrote in chapter 2 is draw_bs_reps(data, func, size=1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
